{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate, Add, PReLU\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from keras import backend as K\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import tensorflow as tf\n",
    "from keras.applications.vgg19 import VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=1024\n",
    "class DataLoader(object):\n",
    "    \n",
    "    def __init__(self, dataset_path=r'./datasets/Soft'):\n",
    "        self.image_height = size\n",
    "        self.image_width = size\n",
    "        self.dataset_path = dataset_path\n",
    "        pass\n",
    "\n",
    "    def imread(self, path):\n",
    "        return scipy.misc.imread(path, mode='RGB').astype(np.float)\n",
    "    \n",
    "    def find_images(self, path):\n",
    "        result = []\n",
    "        for filename in os.listdir(path):\n",
    "            _, ext = os.path.splitext(filename.lower())\n",
    "            if ext == \".jpg\" or ext == \".png\":\n",
    "                result.append(os.path.join(path, filename))\n",
    "                pass\n",
    "            pass\n",
    "        result.sort()\n",
    "        return result\n",
    "    \n",
    "    def load_data(self, batch_size=1, for_testing=False):\n",
    "        search_result = self.find_images(self.dataset_path)\n",
    "        batch_images = np.random.choice(search_result, size=batch_size)\n",
    "        images_A = []\n",
    "        images_B = []\n",
    "        for image_path in batch_images:\n",
    "            combined_image = self.imread(image_path)\n",
    "            h, w, c = combined_image.shape\n",
    "            nW = int(w/2)\n",
    "            image_A, image_B = combined_image[:, :nW, :], combined_image[:, nW:, :]\n",
    "            image_A = scipy.misc.imresize(image_A, (self.image_height, self.image_width))\n",
    "            image_B = scipy.misc.imresize(image_B, (self.image_height, self.image_width))\n",
    "            if not for_testing and np.random.random() < 0.5:\n",
    "        \n",
    "                image_A = np.fliplr(image_A)\n",
    "                image_B = np.fliplr(image_B)\n",
    "                pass\n",
    "            images_A.append(image_A)\n",
    "            images_B.append(image_B)\n",
    "            pass\n",
    "        \n",
    "        images_A = np.array(images_A)/127.5 - 1.\n",
    "        images_B = np.array(images_B)/127.5 - 1.\n",
    "        return images_A, images_B\n",
    "\n",
    "    def load_batch(self, batch_size=1, for_testing=False):\n",
    "        search_result = self.find_images(self.dataset_path)\n",
    "        self.n_complete_batches = int(len(search_result) / batch_size)\n",
    "        for i in range(self.n_complete_batches):\n",
    "            batch = search_result[i*batch_size:(i+1)*batch_size]\n",
    "            images_A, images_B = [], []\n",
    "            for image_path in batch:\n",
    "                combined_image = self.imread(image_path)\n",
    "                h, w, c = combined_image.shape\n",
    "                nW = int(w/2)\n",
    "                image_A = combined_image[:, :nW, :]\n",
    "                image_B = combined_image[:, nW:, :]\n",
    "                image_A = scipy.misc.imresize(image_A, (self.image_height, self.image_width))\n",
    "                image_B = scipy.misc.imresize(image_B, (self.image_height, self.image_width))\n",
    "                if not for_testing and np.random.random() > 0.5:\n",
    "    \n",
    "                    image_A = np.fliplr(image_A)\n",
    "                    image_B = np.fliplr(image_B)\n",
    "                    pass\n",
    "                images_A.append(image_A)\n",
    "                images_B.append(image_B)\n",
    "                pass\n",
    "            images_A = np.array(images_A)/127.5 - 1.\n",
    "            images_B = np.array(images_B)/127.5 - 1.\n",
    "            yield images_A, images_B  \n",
    "class Pix2Pix(object):\n",
    "    def __init__(self):\n",
    "        #Input data\n",
    "        self.img_rows = size\n",
    "        self.img_cols = size\n",
    "        self.img_channels = 3\n",
    "        self.img_vgg_shape = (384,384,3)\n",
    "        self.data_loader = DataLoader()\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.img_channels)\n",
    "        self.image_A = Input(shape = self.img_shape)\n",
    "        self.image_B = Input(shape = self.img_shape)\n",
    "        #Build and compile Discriminator\n",
    "        self.odrate=0.0003\n",
    "        self.ocrate=0.0001\n",
    "        optimizer_d = Adam(self.odrate, 0.5)#0.0001#0.00003\n",
    "        optimizer_c = Adam(self.ocrate, 0.5)#0.0001#0.00003\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss = \"mse\", optimizer = optimizer_d, metrics = ['accuracy'])\n",
    "        #Build Generator\n",
    "        #For the combined model we will only train the generator\n",
    "        self.generator = self.build_generator()\n",
    "        self.fake_A = self.generator(self.image_B)\n",
    "        self.discriminator.trainable = False\n",
    "        self.valid = self.discriminator([self.fake_A, self.image_B])\n",
    "        self.combined = Model(inputs = [self.image_A, self.image_B],outputs = [self.valid, self.fake_A])\n",
    "        self.combined.compile(loss = ['mse',self.vgg_loss],loss_weights = [1, 100], optimizer = optimizer_c)\n",
    "        #Calculate output shape of Discriminator\n",
    "        self.disc_patch = (int(self.img_rows / 2 ** 4), int(self.img_cols / 2 ** 4), 1)\n",
    "        pass\n",
    "\n",
    "    def resblock(self, inputs, out_channel = 32):\n",
    "        x = Conv2D(out_channel, kernel_size = (3,3), padding = \"same\")(inputs)\n",
    "        x = BatchNormalization(momentum=0.8)(x)\n",
    "        x = LeakyReLU(alpha = 0.2)(x)\n",
    "        x = Conv2D(out_channel, kernel_size = (3,3), padding = \"same\")(x)\n",
    "        x = BatchNormalization(momentum=0.8)(x)\n",
    "        x = LeakyReLU(alpha = 0.2)(x)\n",
    "        return Add()([x, inputs])\n",
    "    def build_generator(self,input_shape=(None,None,3)):\n",
    "        inputs = Input(shape = input_shape, name=\"inputs\")\n",
    "        channel = 64\n",
    "        x = Conv2D(channel, kernel_size = (7,7),strides = (1,1), padding = \"same\")(inputs)   #1024*1024\n",
    "        x = LeakyReLU(alpha = 0.2)(x)\n",
    "        x0 = x        \n",
    "        x = Conv2D(channel * 2, kernel_size = (3,3),strides = (2,2), padding = \"same\")(x)   #512*512\n",
    "        for idx in range(15):\n",
    "            x = self.resblock(inputs = x, out_channel = channel * 2)\n",
    "        x = Conv2D(channel, kernel_size = (3,3),strides = (1,1), padding = \"same\")(x)   #512*512\n",
    "        x = LeakyReLU(alpha = 0.2)(x)\n",
    "        x = UpSampling2D((2,2))(x)\n",
    "        x = Add()([x, x0])\n",
    "        x = Conv2D(3, kernel_size = (3,3), padding = \"same\", activation='tanh')(x)\n",
    "        model = Model(inputs, x)\n",
    "        model.summary()\n",
    "        return model\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        # layer 0\n",
    "        def d_layer(layer_input, filters, f_size=4, bn=True):\n",
    "            \"\"\"Discriminator layer\"\"\"\n",
    "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "            d = LeakyReLU(alpha=0.2)(d)\n",
    "            if bn:\n",
    "                d = BatchNormalization(momentum=0.8)(d)\n",
    "            return d\n",
    "        img_A = Input(shape=self.img_shape)\n",
    "        img_B = Input(shape=self.img_shape)\n",
    "        # Concatenate image and conditioning image by channels to produce input\n",
    "        combined_imgs = Concatenate(axis=-1)([img_A, img_B])\n",
    "        d1 = d_layer(combined_imgs, self.df, bn=False)\n",
    "        d2 = d_layer(d1, self.df*2)\n",
    "        d3 = d_layer(d2, self.df*4)\n",
    "        d4 = d_layer(d3, self.df*8)\n",
    "        validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d4)\n",
    "        model = Model([img_A, img_B], validity)\n",
    "        model.summary()\n",
    "        return model\n",
    "\n",
    "    def vgg_loss(self, y_true, y_pred):\n",
    "        \n",
    "        vgg19 = VGG19(include_top=False, weights='imagenet', input_shape=(size,size,3))\n",
    "        vgg19.trainable = False\n",
    "        for l in vgg19.layers:\n",
    "            l.trainable = False\n",
    "        model = Model(inputs=vgg19.input, outputs=vgg19.get_layer('block4_conv4').output)\n",
    "        model.trainable = False\n",
    "        my_true=model(y_true)\n",
    "        my_pred=model(y_pred)\n",
    "        a = K.mean(K.square(my_true - my_pred))\n",
    "        mse = K.mean(K.square(y_pred - y_true), axis=-1)\n",
    "        mae = K.mean(K.abs(y_pred - y_true), axis=-1)\n",
    "        k1 = 0.001\n",
    "        k2 = 0.006\n",
    "        k3 = 0.5\n",
    "        return mae * k1 + a * k2 + mse * k3\n",
    "    \n",
    "    def train(self, epochs, batch_size=1, sample_interval=50, load_pretrained=False):\n",
    "        if load_pretrained:\n",
    "            print('Info: weights loaded.')\n",
    "            self.generator.load_weights('./weights/FaceRetouch/generator_weights_softskin.h5')\n",
    "            self.discriminator.load_weights('./weights/FaceRetouch/discriminator_weights_softskin.h5')\n",
    "            pass\n",
    "        # Adversarial loss ground truths\n",
    "        valid = np.ones((batch_size,) + self.disc_patch)\n",
    "        fake = np.zeros((batch_size,) + self.disc_patch)\n",
    "        for epoch in range(epochs):\n",
    "            for batch_i, (images_A, images_B) in enumerate(self.data_loader.load_batch(batch_size)):\n",
    "                # Condition on B and generate a translated version\n",
    "                fake_A = self.generator.predict(images_B)\n",
    "                # Train the discriminators (original images = real / generated = Fake)\n",
    "                for i in range(0,3):\n",
    "                    d_loss_real = self.discriminator.train_on_batch([images_A, images_B], valid)\n",
    "                    d_loss_fake = self.discriminator.train_on_batch([fake_A, images_B], fake)\n",
    "                    d_loss = 0.5*np.add(d_loss_real ,d_loss_fake)#+ d_loss_fake_tv\n",
    "                # Train the generators\n",
    "                g_loss = self.combined.train_on_batch([images_A, images_B], [valid, images_A])\n",
    "                # Plot the progress\n",
    "                print (\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %3d%%] [G loss: %f]\" % \n",
    "                       (epoch+1, epochs, batch_i+1, self.data_loader.n_complete_batches, \n",
    "                        d_loss[0], 100*d_loss[1], g_loss[0]))\n",
    "                # If at save interval => save generated image samples\n",
    "                if (batch_i+1) % sample_interval == 0:\n",
    "                    self.save_sample_images(epoch+1, batch_i+1)\n",
    "                    pass\n",
    "                if (batch_i+1) % 100 == 0:\n",
    "                    self.generator.save_weights('./weights/FaceRetouch/generator_weights_softskin.h5')\n",
    "                    self.discriminator.save_weights('./weights/FaceRetouch/discriminator_weights_softskin.h5')\n",
    "                    print('Info: weights saved.')\n",
    "                    pass\n",
    "                pass\n",
    "            if (epoch+1) % 10 == 0 :\n",
    "                self.generator.save_weights('./weights/FaceRetouch/generator_weights_softskin'+'.h5')\n",
    "                self.discriminator.save_weights('./weights/FaceRetouch/discriminator_weights_softskin'+'.h5')\n",
    "                print('Info: weights saved.')\n",
    "                pass\n",
    "            pass\n",
    "        self.generator.save_weights('./weights/FaceRetouch/generator_weights_softskin.h5')\n",
    "        self.discriminator.save_weights('./weights/FaceRetouch/discriminator_weights_softskin.h5')\n",
    "        print('Info: weights saved.')\n",
    "        pass\n",
    "    \n",
    "    def save_sample_images(self, epoch, batch_i, save_dir=r'./outputs/SoftCartoon'):\n",
    "        batch_size = 3\n",
    "        images_A, images_B = self.data_loader.load_data(batch_size=batch_size, for_testing=True)\n",
    "        fake_A = self.generator.predict(images_B)\n",
    "        generated_image = Image.new('RGB', (self.img_cols*3, self.img_cols*batch_size))\n",
    "        for b in range(batch_size):\n",
    "            image_A = np.uint8((np.clip(np.array(images_A[b]) * 0.5 + 0.5,0.0,1.0)) * 255)\n",
    "            image_B = np.uint8((np.clip(np.array(images_B[b]) * 0.5 + 0.5,0.0,1.0)) * 255)\n",
    "            image_fake_A = np.uint8((np.clip(np.array(fake_A[b]) * 0.5 + 0.5,0.0,1.0)) * 255)\n",
    "            image_A = Image.fromarray(image_A)\n",
    "            image_B = Image.fromarray(image_B)\n",
    "            image_fake_A = Image.fromarray(image_fake_A)\n",
    "            generated_image.paste(image_B, (0, b*self.img_rows, self.img_cols, (b+1)*self.img_rows))\n",
    "            generated_image.paste(image_fake_A, (self.img_cols, b*self.img_rows, self.img_cols*2, (b+1)*self.img_rows))\n",
    "            generated_image.paste(image_A, (self.img_cols*2, b*self.img_rows, self.img_cols*3, (b+1)*self.img_rows))\n",
    "            pass\n",
    "        generated_image.save(save_dir + \"/G_%d_%d.jpg\" % (epoch, batch_i), quality=95)\n",
    "        pass\n",
    "    \n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = Pix2Pix()\n",
    "gan.train(epochs=50, batch_size=2, sample_interval=50, load_pretrained=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
